{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"EDA_Project\")\n",
    "\n",
    "class KaggleRepository:\n",
    "    def __init__(self, api: KaggleApi):\n",
    "        self.api = api\n",
    "\n",
    "    def download_dataset(self, dataset_name: str, path: str):\n",
    "        try:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            self.api.dataset_download_files(dataset_name, path=path, unzip=True)\n",
    "            logger.info(f\"Dataset {dataset_name} baixado com sucesso em {path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao baixar dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "logger = logging.getLogger(\"EDA_Project\")\n",
    "\n",
    "class AuthKaggle:\n",
    "    def __init__(self, credentials_path: str):\n",
    "        self.credentials_path = credentials_path\n",
    "        self.api = KaggleApi()\n",
    "\n",
    "    def authenticate(self):\n",
    "        try:\n",
    "            with open(self.credentials_path, 'r') as file:\n",
    "                dados = json.load(file)\n",
    "            \n",
    "            os.environ['KAGGLE_USERNAME'] = dados['username']\n",
    "            os.environ['KAGGLE_KEY'] = dados['key']\n",
    "\n",
    "            self.api.authenticate()\n",
    "            logger.info(\"Autenticação bem-sucedida!\")\n",
    "            return self.api\n",
    "        except FileNotFoundError:\n",
    "            logger.error(\"Arquivo de credenciais não encontrado!\")\n",
    "        except json.JSONDecodeError:\n",
    "            logger.error(\"JSON inválido!\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro na autenticação: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from adapters.kaggle_repo import KaggleRepository\n",
    "# from domain.interfaces.repositories import IKaggleRepository\n",
    "\n",
    "# class DatasetInfo:\n",
    "#     def __init__(self, repo: IKaggleRepository):\n",
    "#         self.repo = repo\n",
    "\n",
    "#     def get_info(self, dataset_name: str):\n",
    "#         return self.repo.get_dataset_metadata(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "import dtale\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"EDA_Project\")\n",
    "\n",
    "class EDAReport:\n",
    "    def __init__(self, dataset_path: str):\n",
    "        try:\n",
    "            self.dataset = pd.read_csv(dataset_path)\n",
    "            logger.info(f\"Dataset carregado com sucesso: {dataset_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao carregar o dataset: {e}\")\n",
    "            self.dataset = None\n",
    "\n",
    "    def generate_autoviz(self):\n",
    "        if self.dataset is not None:\n",
    "            av = AutoViz_Class()\n",
    "            av.AutoViz(self.dataset)\n",
    "        else:\n",
    "            logger.error(\"Dataset não carregado. Relatório AutoViz não pode ser gerado.\")\n",
    "\n",
    "    def generate_sweetviz(self):\n",
    "        if self.dataset is not None:\n",
    "            report = sv.analyze(self.dataset)\n",
    "            report.show_html(\"sweetviz_report.html\")\n",
    "        else:\n",
    "            logger.error(\"Dataset não carregado. Relatório Sweetviz não pode ser gerado.\")\n",
    "\n",
    "    def generate_dtale(self):\n",
    "        if self.dataset is not None:\n",
    "            dtale.show(self.dataset)\n",
    "        else:\n",
    "            logger.error(\"Dataset não carregado. Relatório D-Tale não pode ser gerado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from abc import ABC, abstractmethod\n",
    "\n",
    "# class IKaggleRepository(ABC):\n",
    "#     @abstractmethod\n",
    "#     def download_dataset(self, dataset_name: str, path: str):\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def get_dataset_metadata(self, dataset_name: str) -> dict:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def setup_logger():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"logs.txt\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(\"EDA_Project\")\n",
    "\n",
    "logger = setup_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:37:32,411 - INFO - Iniciando autenticação no Kaggle.\n",
      "2025-03-09 15:37:32,475 - INFO - Autenticação bem-sucedida!\n",
      "2025-03-09 15:37:32,479 - INFO - Autenticação bem-sucedida! Fazendo download do dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rkiattisak/luxury-watches-price-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:37:33,934 - INFO - Dataset rkiattisak/luxury-watches-price-dataset baixado com sucesso em C:\\Users\\MatheusBenatti/Desktop/ProjetoLuxuryWatches/content\n",
      "2025-03-09 15:37:33,936 - INFO - Dataset baixado com sucesso! Gerando relatórios de EDA.\n",
      "2025-03-09 15:37:33,965 - INFO - Dataset carregado com sucesso: C:\\Users\\MatheusBenatti/Desktop/ProjetoLuxuryWatches/content\\Luxury Watch.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of your Data Set loaded: (507, 14)\n",
      "#######################################################################################\n",
      "######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
      "#######################################################################################\n",
      "Classifying variables in data set...\n",
      "    Number of Numeric Columns =  3\n",
      "    Number of Integer-Categorical Columns =  0\n",
      "    Number of String-Categorical Columns =  10\n",
      "    Number of Factor-Categorical Columns =  0\n",
      "    Number of String-Boolean Columns =  0\n",
      "    Number of Numeric-Boolean Columns =  0\n",
      "    Number of Discrete String Columns =  1\n",
      "    Number of NLP String Columns =  0\n",
      "    Number of Date Time Columns =  0\n",
      "    Number of ID Columns =  0\n",
      "    Number of Columns to Delete =  0\n",
      "    14 Predictors classified...\n",
      "        No variables removed since no ID or low-information variables found in data set\n",
      "To fix these data quality issues in the dataset, import FixDQ from autoviz...\n",
      "There are 19 duplicate rows in your dataset\n",
      "    Alert: Dropping duplicate rows can sometimes cause your column data types to change to object!\n",
      "    All variables classified into correct types.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1f55c_row0_col0, #T_1f55c_row0_col2, #T_1f55c_row0_col3, #T_1f55c_row0_col4, #T_1f55c_row0_col5, #T_1f55c_row1_col0, #T_1f55c_row1_col2, #T_1f55c_row1_col3, #T_1f55c_row1_col4, #T_1f55c_row1_col5, #T_1f55c_row2_col0, #T_1f55c_row2_col2, #T_1f55c_row2_col3, #T_1f55c_row2_col4, #T_1f55c_row2_col5, #T_1f55c_row3_col0, #T_1f55c_row3_col2, #T_1f55c_row3_col3, #T_1f55c_row3_col4, #T_1f55c_row3_col5, #T_1f55c_row4_col0, #T_1f55c_row4_col2, #T_1f55c_row4_col3, #T_1f55c_row4_col4, #T_1f55c_row4_col5, #T_1f55c_row5_col0, #T_1f55c_row5_col2, #T_1f55c_row5_col3, #T_1f55c_row5_col4, #T_1f55c_row5_col5, #T_1f55c_row6_col0, #T_1f55c_row6_col2, #T_1f55c_row6_col3, #T_1f55c_row6_col4, #T_1f55c_row6_col5, #T_1f55c_row7_col0, #T_1f55c_row7_col2, #T_1f55c_row7_col3, #T_1f55c_row7_col4, #T_1f55c_row7_col5, #T_1f55c_row8_col0, #T_1f55c_row8_col2, #T_1f55c_row8_col3, #T_1f55c_row8_col4, #T_1f55c_row8_col5, #T_1f55c_row9_col0, #T_1f55c_row9_col2, #T_1f55c_row9_col3, #T_1f55c_row9_col4, #T_1f55c_row9_col5, #T_1f55c_row10_col0, #T_1f55c_row10_col2, #T_1f55c_row10_col3, #T_1f55c_row10_col4, #T_1f55c_row10_col5, #T_1f55c_row11_col0, #T_1f55c_row11_col2, #T_1f55c_row11_col3, #T_1f55c_row11_col4, #T_1f55c_row11_col5, #T_1f55c_row12_col0, #T_1f55c_row12_col2, #T_1f55c_row12_col3, #T_1f55c_row12_col4, #T_1f55c_row12_col5, #T_1f55c_row13_col0, #T_1f55c_row13_col2, #T_1f55c_row13_col3, #T_1f55c_row13_col4, #T_1f55c_row13_col5 {\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_1f55c_row0_col1, #T_1f55c_row1_col1, #T_1f55c_row2_col1, #T_1f55c_row3_col1, #T_1f55c_row4_col1, #T_1f55c_row5_col1, #T_1f55c_row6_col1, #T_1f55c_row7_col1, #T_1f55c_row8_col1, #T_1f55c_row9_col1, #T_1f55c_row10_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_1f55c_row11_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_1f55c_row12_col1 {\n",
       "  background-color: #fee3d6;\n",
       "  color: #000000;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_1f55c_row13_col1 {\n",
       "  background-color: #fff4ee;\n",
       "  color: #000000;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1f55c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1f55c_level0_col0\" class=\"col_heading level0 col0\" >Data Type</th>\n",
       "      <th id=\"T_1f55c_level0_col1\" class=\"col_heading level0 col1\" >Missing Values%</th>\n",
       "      <th id=\"T_1f55c_level0_col2\" class=\"col_heading level0 col2\" >Unique Values%</th>\n",
       "      <th id=\"T_1f55c_level0_col3\" class=\"col_heading level0 col3\" >Minimum Value</th>\n",
       "      <th id=\"T_1f55c_level0_col4\" class=\"col_heading level0 col4\" >Maximum Value</th>\n",
       "      <th id=\"T_1f55c_level0_col5\" class=\"col_heading level0 col5\" >DQ Issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row0\" class=\"row_heading level0 row0\" >Brand</th>\n",
       "      <td id=\"T_1f55c_row0_col0\" class=\"data row0 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row0_col2\" class=\"data row0 col2\" >7</td>\n",
       "      <td id=\"T_1f55c_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row0_col4\" class=\"data row0 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row0_col5\" class=\"data row0 col5\" >15 rare categories: Too many to list. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row1\" class=\"row_heading level0 row1\" >Model</th>\n",
       "      <td id=\"T_1f55c_row1_col0\" class=\"data row1 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row1_col2\" class=\"data row1 col2\" >19</td>\n",
       "      <td id=\"T_1f55c_row1_col3\" class=\"data row1 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row1_col4\" class=\"data row1 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row1_col5\" class=\"data row1 col5\" >65 rare categories: Too many to list. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row2\" class=\"row_heading level0 row2\" >Case Material</th>\n",
       "      <td id=\"T_1f55c_row2_col0\" class=\"data row2 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row2_col2\" class=\"data row2 col2\" >3</td>\n",
       "      <td id=\"T_1f55c_row2_col3\" class=\"data row2 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row2_col4\" class=\"data row2 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row2_col5\" class=\"data row2 col5\" >9 rare categories: ['18K Rose Gold', 'Carbon Fiber', '18K Yellow Gold', 'German Submarine Steel', 'High-Tech Ceramic', 'Bronze', 'Yellow Gold', '18k King Gold', '18k Yellow Gold']. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row3\" class=\"row_heading level0 row3\" >Strap Material</th>\n",
       "      <td id=\"T_1f55c_row3_col0\" class=\"data row3 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row3_col2\" class=\"data row3 col2\" >2</td>\n",
       "      <td id=\"T_1f55c_row3_col3\" class=\"data row3 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row3_col4\" class=\"data row3 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row3_col5\" class=\"data row3 col5\" >8 rare categories: ['NATO Strap', 'Jubilee Bracelet', 'Jubilee', 'Alligator', 'Rose Gold', 'Titanium', 'Textile', 'NATO strap']. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row4\" class=\"row_heading level0 row4\" >Movement Type</th>\n",
       "      <td id=\"T_1f55c_row4_col0\" class=\"data row4 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_1f55c_row4_col3\" class=\"data row4 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row4_col4\" class=\"data row4 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row4_col5\" class=\"data row4 col5\" >1 rare categories: ['Eco-Drive']. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row5\" class=\"row_heading level0 row5\" >Water Resistance</th>\n",
       "      <td id=\"T_1f55c_row5_col0\" class=\"data row5 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row5_col2\" class=\"data row5 col2\" >2</td>\n",
       "      <td id=\"T_1f55c_row5_col3\" class=\"data row5 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row5_col4\" class=\"data row5 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row5_col5\" class=\"data row5 col5\" >4 rare categories: ['1000 meters', '500 meters', '600 meters', '2000 meters']. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row6\" class=\"row_heading level0 row6\" >Case Diameter (mm)</th>\n",
       "      <td id=\"T_1f55c_row6_col0\" class=\"data row6 col0\" >float64</td>\n",
       "      <td id=\"T_1f55c_row6_col1\" class=\"data row6 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row6_col2\" class=\"data row6 col2\" >NA</td>\n",
       "      <td id=\"T_1f55c_row6_col3\" class=\"data row6 col3\" >27.500000</td>\n",
       "      <td id=\"T_1f55c_row6_col4\" class=\"data row6 col4\" >46.500000</td>\n",
       "      <td id=\"T_1f55c_row6_col5\" class=\"data row6 col5\" >Column has 26 outliers greater than upper bound (45.00) or lower than lower bound(37.00). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row7\" class=\"row_heading level0 row7\" >Case Thickness (mm)</th>\n",
       "      <td id=\"T_1f55c_row7_col0\" class=\"data row7 col0\" >float64</td>\n",
       "      <td id=\"T_1f55c_row7_col1\" class=\"data row7 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row7_col2\" class=\"data row7 col2\" >NA</td>\n",
       "      <td id=\"T_1f55c_row7_col3\" class=\"data row7 col3\" >5.000000</td>\n",
       "      <td id=\"T_1f55c_row7_col4\" class=\"data row7 col4\" >17.500000</td>\n",
       "      <td id=\"T_1f55c_row7_col5\" class=\"data row7 col5\" >No issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row8\" class=\"row_heading level0 row8\" >Band Width (mm)</th>\n",
       "      <td id=\"T_1f55c_row8_col0\" class=\"data row8 col0\" >float64</td>\n",
       "      <td id=\"T_1f55c_row8_col1\" class=\"data row8 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row8_col2\" class=\"data row8 col2\" >NA</td>\n",
       "      <td id=\"T_1f55c_row8_col3\" class=\"data row8 col3\" >15.000000</td>\n",
       "      <td id=\"T_1f55c_row8_col4\" class=\"data row8 col4\" >28.000000</td>\n",
       "      <td id=\"T_1f55c_row8_col5\" class=\"data row8 col5\" >Column has 9 outliers greater than upper bound (25.00) or lower than lower bound(17.00). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row9\" class=\"row_heading level0 row9\" >Dial Color</th>\n",
       "      <td id=\"T_1f55c_row9_col0\" class=\"data row9 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row9_col1\" class=\"data row9 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row9_col2\" class=\"data row9 col2\" >1</td>\n",
       "      <td id=\"T_1f55c_row9_col3\" class=\"data row9 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row9_col4\" class=\"data row9 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row9_col5\" class=\"data row9 col5\" >3 rare categories: ['Ivory', 'Champagne', 'Grey']. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row10\" class=\"row_heading level0 row10\" >Crystal Material</th>\n",
       "      <td id=\"T_1f55c_row10_col0\" class=\"data row10 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row10_col1\" class=\"data row10 col1\" >0.000000</td>\n",
       "      <td id=\"T_1f55c_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_1f55c_row10_col3\" class=\"data row10 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row10_col4\" class=\"data row10 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row10_col5\" class=\"data row10 col5\" >2 rare categories: ['Hardlex', 'Mineral']. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row11\" class=\"row_heading level0 row11\" >Complications</th>\n",
       "      <td id=\"T_1f55c_row11_col0\" class=\"data row11 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row11_col1\" class=\"data row11 col1\" >24.180328</td>\n",
       "      <td id=\"T_1f55c_row11_col2\" class=\"data row11 col2\" >5</td>\n",
       "      <td id=\"T_1f55c_row11_col3\" class=\"data row11 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row11_col4\" class=\"data row11 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row11_col5\" class=\"data row11 col5\" >118 missing values. Impute them with mean, median, mode, or a constant value such as 123., 18 rare categories: Too many to list. Group them into a single category or drop the categories., Mixed dtypes: has 2 different data types:  object, float,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row12\" class=\"row_heading level0 row12\" >Power Reserve</th>\n",
       "      <td id=\"T_1f55c_row12_col0\" class=\"data row12 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row12_col1\" class=\"data row12 col1\" >2.663934</td>\n",
       "      <td id=\"T_1f55c_row12_col2\" class=\"data row12 col2\" >5</td>\n",
       "      <td id=\"T_1f55c_row12_col3\" class=\"data row12 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row12_col4\" class=\"data row12 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row12_col5\" class=\"data row12 col5\" >13 missing values. Impute them with mean, median, mode, or a constant value such as 123., 6 rare categories: ['80 hours', '270 days', '4,200', '210 days', '41 hours', '168 hours']. Group them into a single category or drop the categories., Mixed dtypes: has 2 different data types:  object, float,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f55c_level0_row13\" class=\"row_heading level0 row13\" >Price (USD)</th>\n",
       "      <td id=\"T_1f55c_row13_col0\" class=\"data row13 col0\" >object</td>\n",
       "      <td id=\"T_1f55c_row13_col1\" class=\"data row13 col1\" >0.204918</td>\n",
       "      <td id=\"T_1f55c_row13_col2\" class=\"data row13 col2\" >37</td>\n",
       "      <td id=\"T_1f55c_row13_col3\" class=\"data row13 col3\" ></td>\n",
       "      <td id=\"T_1f55c_row13_col4\" class=\"data row13 col4\" ></td>\n",
       "      <td id=\"T_1f55c_row13_col5\" class=\"data row13 col5\" >1 missing values. Impute them with mean, median, mode, or a constant value such as 123., Mixed dtypes: has 2 different data types:  object, float,, Possible high cardinality column with 182 unique values: Use hash encoding or text embedding to reduce dimension.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a3e294a960>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Scatter Plots = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\MatheusBenatti\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]    |     ...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Plots done\n",
      "Time to run AutoViz = 3 seconds \n",
      "\n",
      " ###################### AUTO VISUALIZATION Completed ########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:37:49,659 - INFO - Processo concluído com sucesso.\n"
     ]
    }
   ],
   "source": [
    "#Datasets utilizados: https://www.kaggle.com/datasets/philmorekoung11/luxury-watch-listings (40mb) e https://www.kaggle.com/datasets/rkiattisak/luxury-watches-price-dataset (60kb)\n",
    "#generate_sweetviz não executa com as versões NumPy mais recentes.\n",
    "import os\n",
    "from application.use_cases.auth_kaggle import AuthKaggle\n",
    "from adapters.kaggle_repo import KaggleRepository\n",
    "from application.use_cases.eda_report import EDAReport\n",
    "from infrastructure.logger import logger\n",
    "\n",
    "# Caminhos\n",
    "credentials_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "download_path = os.path.expanduser(\"~/Desktop/ProjetoLuxuryWatches/content\")\n",
    "#dataset_name = \"philmorekoung11/luxury-watch-listings\"\n",
    "dataset_name = \"rkiattisak/luxury-watches-price-dataset\"\n",
    "#dataset_path = os.path.join(download_path, \"Watches.csv\")\n",
    "dataset_path = os.path.join(download_path, \"Luxury Watch.csv\")\n",
    "\n",
    "# Autenticação\n",
    "logger.info(\"Iniciando autenticação no Kaggle.\")\n",
    "auth = AuthKaggle(credentials_path)\n",
    "api = auth.authenticate()\n",
    "\n",
    "if api:\n",
    "    logger.info(\"Autenticação bem-sucedida! Fazendo download do dataset.\")\n",
    "    repo = KaggleRepository(api)\n",
    "    repo.download_dataset(dataset_name, download_path)\n",
    "else:\n",
    "    logger.error(\"Falha na autenticação do Kaggle. Encerrando aplicação.\")\n",
    "    exit()\n",
    "\n",
    "# Verifica se o dataset foi baixado\n",
    "if not os.path.exists(dataset_path):\n",
    "    logger.error(f\"Arquivo {dataset_path} não encontrado após o download.\")\n",
    "    exit()\n",
    "\n",
    "# Análise exploratória\n",
    "logger.info(\"Dataset baixado com sucesso! Gerando relatórios de EDA.\")\n",
    "eda = EDAReport(dataset_path)\n",
    "eda.generate_autoviz()\n",
    "#eda.generate_sweetviz()\n",
    "eda.generate_dtale()\n",
    "eda.generate_ydata()\n",
    "\n",
    "logger.info(\"Processo concluído com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
